{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual State Classification (Python 3)\n",
    "## <div id=\"content\">Contents</div>\n",
    "1. <a href=\"#arch\">Model Specification</a> \n",
    "2. <a href=\"#train\">Training</a> \n",
    "3. <a href=\"#test\">Testing</a> \n",
    "4. <a href=\"#visual\">Visualisations</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ $(id -u) = 0 ];\n",
    "then\n",
    "    echo \"You are root\" # Should be root!\n",
    "else\n",
    "    echo \"You do not have the right priviliges, you must be root\"  \n",
    "fi\n",
    "python3 -V\n",
    "nvcc --version # Should be 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Must be using Python 3\")\n",
    "\n",
    "from IPython.display import clear_output # Clear Outpuopencv-pythont in cell programmatically\n",
    "from ipywidgets import IntProgress # Progress Bar\n",
    "import os, sys, shutil #Advanced File Manipulation\n",
    "from os import path\n",
    "import glob\n",
    "import matplotlib as mlt # Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "#import opencv_python as cv2 # Interpret camera images\n",
    "import pandas, numpy # Data Manipulation\n",
    "from termcolor import colored # Colored Text\n",
    "\n",
    "import subprocess # Used to run scripts in the background\n",
    "import signal # Used to signal OS (e.g. to kill a process)\n",
    "import csv # easily read and write to CSV files (used for ground truths)\n",
    "import math # For trigonometry\n",
    "import json # Effeciently store data structures\n",
    "\n",
    "# Hyper-parameter Optimization Modules\n",
    "import types as types\n",
    "from types import * # Special Types (e.g. classes)\n",
    "import inspect # Inspect method/class signatures\n",
    "import pickle # Effeciently store classes to file\n",
    "\n",
    "\n",
    "import getpass # For sudo-based tasks (hides input)\n",
    "import re # Regular expressions\n",
    "import random # For variation\n",
    "import copy\n",
    "import time # Allow python to wait\n",
    "from enum import Enum\n",
    "\n",
    "# Machine Learning\n",
    "import numpy as np\n",
    "import torch # Deep Learning research library\n",
    "import torchsnooper\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "# >>> Utilities <<<\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "class label(Enum):\n",
    "    GRASP = 0\n",
    "    BAD = 1\n",
    "    NOT_READY = 2\n",
    "    EMPTY = 3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup CUDA path on Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = subprocess.check_output(\"source ./switch_cuda.sh 10.1; env -0\", shell=True,\n",
    "                      executable=\"/bin/bash\")\n",
    "\n",
    "os.environ.update({\"CUDA_HOME\":\"/usr/local/cuda-10.1\"})\n",
    "print(dict(os.environ)[\"CUDA_HOME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"arch\">Model Specification</span>\n",
    "<a href=\"#content\">Return to Contents</a>\n",
    "\n",
    "As we are working with spatio-temporal data where the time series component is potentially very informative, a Residual Neural Network (ResNet) with additional Long-Short Term Memory (LSTM) layers is appropriate. The residual components allow for feedback between layers while the LSTM enables the history of states to be remembered and exploited for better performance.\n",
    "\n",
    "In this tiered development approach, the complexity of models is increased progressively to accomodate new features and determine more useful outputs. For appropriate fallback and baseline comparisons, earlier - functional - architectures for each model are retained here. Models are grouped by type and internally ordered by complexity, simplest first.\n",
    "\n",
    "### <span id=\"arch-content\">Section Contents</span>\n",
    "\n",
    "1. <a href=\"#grasp\">Grasp Point Extraction</a>\n",
    "    1. <a href=\"#grasp\">Detection</a>\n",
    "    2. <a href=\"#grasp-centroid\">Centroid Extraction</a>\n",
    "    3. <a href=\"#grasp-orientation\">Orientation Extraction</a>\n",
    "2. <a href=\"#pick\">Pick-And-Place</a>\n",
    "    1. <a href=\"#pick-semi\">Semi-supervised</a>\n",
    "    2. <a href=\"#pick-simul\">Unsupervised in simulation</a>\n",
    "    3. <a href=\"#pick-real\">Unsupervised in reality</a>\n",
    "    4. <a href=\"#pick-placement\">Placement</a>\n",
    "    5. <a href=\"#pick-haptic\">Haptic</a>\n",
    "3. <a href=\"#waste\">Waste Category Classifier</a>\n",
    "    1. <a href=\"#waste-material\">By Material</a>\n",
    "    2. <a href=\"#waste-type\">By Type</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"train\">Training</span>\n",
    "<a href=\"#content\">Return to Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options\n",
    "Our intention is to abstract out hyperparameters in the neural network (and create a \"master\" class for \"instantiate\" training sessions). To do so all relevant hyperpameters must be identified and validated. Hence, in this section we define the infrastructure needed to define which hyperparameter options exist. This includes their exact_name (as a string) and their possible values (type or list).\n",
    "\n",
    "Identified Hyperparmaters:\n",
    "1.   Loss Function\n",
    "2.   Activation Function\n",
    "3.   Optimizer\n",
    "4.   Number of epochs\n",
    "5.   Batch Size\n",
    "6.   Shuffler\n",
    "7.   Transformer\n",
    "  *   Resizing\n",
    "  *   Cropping\n",
    "  *   Normalization\n",
    "  *   ColourSpace \n",
    "  *   Contrast\n",
    "8. Dropout probability\n",
    "9. Architecture\n",
    "10. Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options(object):\n",
    "    def __init__(self, id, filePath=None, **kwargs):\n",
    "        self.id = id\n",
    "        if filePath is not None:\n",
    "            with open(filePath, 'rb') as handle:\n",
    "                d = pickle.load(handle)\n",
    "                for key, value in d.items():\n",
    "                    if key == \"id\":\n",
    "                        continue\n",
    "                    exec(\"self.{}={}\".format(key,value if type(value) is list else value.__name__))\n",
    "        print(type(kwargs), len(kwargs))\n",
    "        self.add_options(kwargs)\n",
    "\n",
    "    def get(self, name):\n",
    "        if hasattr(self, name):\n",
    "            return eval(\"self.{}\".format(name))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_module_classes(self, moduleName):\n",
    "\n",
    "        try:\n",
    "            exec(\"import {}\".format(moduleName))\n",
    "        except:\n",
    "            raise ImportError(\"Module {}\".format(moduleName))\n",
    "\n",
    "        black_list = [\"List\", ]\n",
    "        func_list = []\n",
    "        # ToDo: Select functions to REMOVE not to INCLUDE\n",
    "        count = 0\n",
    "        func_dict = {}\n",
    "        for func in dir(eval(moduleName)):\n",
    "            if re.search(\"__\", func) or re.search(\"^_|_$\", func) or func in black_list:\n",
    "                continue\n",
    "\n",
    "            desc = eval(\"{}.{}.__doc__\".format(moduleName,func))\n",
    "            if desc is None:\n",
    "                desc = \"No Description Found\"\n",
    "            else:\n",
    "                desc = desc.split(\"\\n\")[0]\n",
    "            print(\"{}: {}{}{} ({})\".format(count,color.BOLD,func,color.END,desc))\n",
    "\n",
    "            func_dict[count] = func\n",
    "            count += 1\n",
    "\n",
    "        resp = raw_input(\"Provide digit (e.g. 3), or list of digits (e.g. 2,4,6 ), of elements to IGNORE\")\n",
    "\n",
    "        while resp != \"x\":\n",
    "            print(\"'{}'\".format(resp))\n",
    "            numbers = resp.split(\",\")\n",
    "            for number in numbers:\n",
    "                if number.isdigit():\n",
    "                    try:\n",
    "                        del func_dict[int(number)]\n",
    "                    except:\n",
    "                        print(\"Could not remove '{}' from elements\")\n",
    "                else:\n",
    "                    print(\"{} is not a digit\".format(number))\n",
    "\n",
    "            print(\"--------------\")\n",
    "            # clear_output(wait=True)\n",
    "\n",
    "            for count, func in func_dict.items():\n",
    "                desc = eval(\"{}.{}.__doc__\".format(moduleName,func))\n",
    "                if desc is None:\n",
    "                    desc = \"No Description Found\"\n",
    "                else:\n",
    "                    desc = desc.split(\"\\n\")[0]\n",
    "                print(\"{}: {}{}{} ({})\".format(count,color.BOLD,func,color.END,desc))\n",
    "            resp = raw_input(\"Provide digit or list of digits to ignore, 'x' to exit\")\n",
    "\n",
    "        return [\"{}.{}\".format(moduleName,value) for value in func_dict.values()]\n",
    "\n",
    "    def add_options(self, options):\n",
    "        if type(options) is not dict:\n",
    "            raise TypeError(\n",
    "                \"Option must be a dictionary \\{name:type OR list\\}\")\n",
    "        for key, value in options.items():\n",
    "            print(\"{}:{}\".format(key,value))\n",
    "            if type(key) is str and type(value) is type:\n",
    "                exec(\"self.{}={}\".format(key,value.__name__))  # int\n",
    "            elif type(key) is str and type(value) is str:\n",
    "                exec(\"self.{}={}\".format(key,self.get_module_classes(value)))\n",
    "            elif type(key) is str and type(value) is list:\n",
    "                exec(\"self.{}={}\".format(key,value))\n",
    "            else:\n",
    "                raise TypeError(\"Key must be str, value must be type or list\")\n",
    "\n",
    "    def remove_option(self, name):\n",
    "        if hasasttr(self, name):\n",
    "            delattr(self, name)\n",
    "            print(\"Removed attribute {} from options\".format(name))\n",
    "\n",
    "    def save_options(self, dirPath):\n",
    "        d = self.__dict__\n",
    "        file_path = os.path.join(dirPath, 'options_{}.pickle'.format(self.id))\n",
    "        if os.path.exists(file_path):\n",
    "            raise ValueError(\"{} already exists\".format(file_path))\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Saved options to file:\\n{}\".format(file_path))\n",
    "\n",
    "    def __str__(self):\n",
    "        info_str = \">>> {0}Options {2}{1} <<<\\n\".format(color.BOLD,color.END,self.id)\n",
    "        for key,value in vars(self).items():\n",
    "            info_str += \"\\n{0}{2}{1}={3}\\n\".format(color.BOLD,color.END,key,value)\n",
    "        return info_str\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Options from File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options(\"basic\",filePath=path.join(os.getcwd(),\"options\",\"options_basic.pickle\"))\n",
    "print(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a new Options instance**\n",
    "\n",
    "Acts as a blueprint for hyperparameters. That is it identifies which hyperparameters exist and how they can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: For convenience we've limited the models to Classification, feel free to remove this\n",
    "classification_architectures = [\"torchvision.models.alexnet\",\"torchvision.models.vgg11\",\"torchvision.models.vgg11_bn\",\"torchvision.models.vgg13\",\n",
    "                \"torchvision.models.vgg13_bn\",\"torchvision.models.vgg16\",\"torchvision.models.vgg16_bn\",\"torchvision.models.vgg19\",\n",
    "                \"torchvision.models.vgg19_bn\",\"torchvision.models.resnet18\",\"torchvision.models.resnet34\",\"torchvision.models.resnet50\",\n",
    "                \"torchvision.models.resnet101\",\"torchvision.models.resnet152\",\"torchvision.models.squeezenet1_0\",\"torchvision.models.squeezenet1_1\",\n",
    "                \"torchvision.models.densenet121\",\"torchvision.models.densenet169\",\"torchvision.models.densenet161\",\"torchvision.models.densenet201\",\n",
    "                \"torchvision.models.googlenet\",\"torchvision.models.shufflenet_v2_x0_5\",\"torchvision.models.shufflenet_v2_x1_0\",\"torchvision.models.shufflenet_v2_x1_5\",\n",
    "                \"torchvision.models.shufflenet_v2_x2_0\",\"torchvision.models.mobilenet_v2\",\"torchvision.models.resnext50_32x4d\",\"torchvision.models.resnext101_32x8d\",\n",
    "                \"torchvision.models.wide_resnet50_2\",\"torchvision.models.wide_resnet101_2\",\"torchvision.models.mnasnet0_5\",\"torchvision.models.mnasnet0_75\",\n",
    "                \"torchvision.models.mnasnet1_0\",\"torchvision.models.mnasnet1_3\",\"torchvision.models.inception_v3\"]\n",
    "\n",
    "name = input(\"Name for new options\")\n",
    "options_new = Options(name,filePath=None,**{\"loss\":\"torch.nn.modules.loss\",\n",
    "                                   \"activation\":\"torch.nn.modules.activation\",\n",
    "                                   \"optimizer\":\"torch.optim\",\n",
    "                                   \"no_epochs\":int,\n",
    "                                   \"batch_size\":int,\n",
    "                                   \"shuffle\":bool,\n",
    "                                   \"architecture\":classification_architectures,\n",
    "                                   \"dropout_probability\":float,\n",
    "                                   \"learning_rate\":float})\n",
    "\n",
    "options_new.save_options(path.join(os.getcwd(),\"options\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "Provides a unique configuration for the hyperparameters to be passed to the Training Pipeline. It uses the Options Class to define which hyper-parameters may exist. The config maps hyper-parameters names to one specific value. This way we can easily add new configurations (and put those Config objects in a list) to queue many different hyperparameter combinations for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    options = None\n",
    "\n",
    "    def __init__(self, file_path=None, options=None, verbose = False, **kwargs):\n",
    "        if file_path is not None:\n",
    "            if verbose: print(\"Loading configuration from {}\".format(file_path.split(os.path.sep)[-1]))\n",
    "            with open(file_path, 'rb') as handle:\n",
    "                d = pickle.load(handle)\n",
    "                for key, value in d.items():\n",
    "                    value, kwargs = value\n",
    "                    if verbose: print(key, str(value), type(value))\n",
    "                    if type(value) is str:\n",
    "                        exec(\"self.{} = ('{}',{})\".format(key,value,kwargs))\n",
    "                    else:\n",
    "                        exec(\"self.{}=({},{})\".format(key,value,kwargs))\n",
    "            self.configured = (True, None)\n",
    "            return\n",
    "\n",
    "        if Config.options is None:\n",
    "            if isinstance(options, Options):\n",
    "                print(\"Setting Options for all Config Instances\")\n",
    "                Config.options = options\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    \"Options must be provided on 1st instance of Config Class\")\n",
    "\n",
    "        if len(kwargs) > 1:\n",
    "            for key, value in kwargs.items():\n",
    "                if Config.options.get(key) is not None:\n",
    "                    try:\n",
    "                        value, kwargs = value\n",
    "                        if type(value) is str:\n",
    "                            exec(\"self.{}=('{}',{})\".format(key,value,kwargs))\n",
    "                        else:\n",
    "                            exec(\"self.{}=({},{})\".format(key,value,kwargs))\n",
    "                    except:\n",
    "                        exec(\"self.{}=({},None)\".format(key,value))\n",
    "                else:\n",
    "                    raise NameError(\"{} not found in available hyperparameters.\".format(key))\n",
    "            self.configured = (True, None)\n",
    "        else:\n",
    "            self.configured = (False, None)\n",
    "\n",
    "    def config_wizard(self):\n",
    "        if self.configured[0]:\n",
    "            print(\"Already Configured {}\".format(id(self)))\n",
    "            return False  # Unsuccessful\n",
    "\n",
    "        for option_name, abstract_val in Config.options.__dict__.items():\n",
    "            # abstract_val = eval(f\"options.{option_name}\")\n",
    "\n",
    "            is_typed = False\n",
    "            if option_name == \"id\":\n",
    "                continue\n",
    "            print(\">>> Choose {} <<<\".format(option_name))\n",
    "            if type(abstract_val) is list:\n",
    "                print('\\n'.join(\"{}: {}\".format(i,abstract_val[i]) for i in range(len(abstract_val))))\n",
    "            else:\n",
    "                is_typed = True\n",
    "                print(abstract_val)\n",
    "                print(\"Enter value of Type {}\".format(abstract_val.__name__))\n",
    "            resp = input()\n",
    "            while True:\n",
    "                if is_typed == True:\n",
    "                    try:\n",
    "                        specific_val = abstract_val(resp)\n",
    "                    except:\n",
    "                        resp = input(\"Please enter value of type {}\".format(abstract_val.__name__))\n",
    "                        continue\n",
    "                    exec(\"self.{} = ({},None)\".format(option_name,specific_val)) in locals()\n",
    "                    break\n",
    "                else:  # Not Typed\n",
    "                    if resp.isdigit():\n",
    "                        try:\n",
    "                            specific_val = abstract_val[int(resp)]\n",
    "                        except:\n",
    "                            resp = input(\"Please pick an integer index in range {}\".format(len(abstract_val)))\n",
    "                            continue\n",
    "\n",
    "                        #*package, method = specific_val.split('.')\n",
    "                        exec(\"import {}\".format('.'.join(specific_val.split('.')[:-1]))) in locals()\n",
    "                        print(specific_val)\n",
    "                        \n",
    "                        method = eval(specific_val)\n",
    "                        # >>> Display Optional Parameters <<<\n",
    "                        counter = 0\n",
    "                        valid_counts = []; kwargs = {}\n",
    "                        args,varargs,keywords,defaults = inspect.getargspec(method.__init__ if inspect.isclass(method) else method)\n",
    "                        if defaults is not None:\n",
    "                            offset = len(args)-len(defaults)\n",
    "                            for i in range(offset,len(args)):\n",
    "                                key, default_value = args[i], defaults[i-offset]\n",
    "\n",
    "                                if default_value not in [None]:\n",
    "                                    print(\"{}: {} [Default:{}]\".format(counter,key,default_value))\n",
    "                                    valid_counts.append(counter)\n",
    "                                counter += 1\n",
    "\n",
    "                            if len(valid_counts) > 0:\n",
    "                                resp = input(\"Select parameter by number (e.g. 0), or ENTER to continue\")\n",
    "                                while resp:\n",
    "                                    if resp.isdigit():\n",
    "                                        if int(resp) in valid_counts:\n",
    "                                            key, default_value = args[int(resp)+offset], defaults[int(resp)]\n",
    "                                            new_value = input(\"Enter new value of type {} [Default: {}]\".format(type(default_value).__name__,\n",
    "                                                                                                                default_value))\n",
    "                                            while new_value:\n",
    "                                                try:\n",
    "                                                    new_default_val = type(default_value)(new_value)\n",
    "                                                    break\n",
    "                                                except:\n",
    "                                                    new_value = input(\"Enter new value of type {} [Default: {}]\".format(type(default_value).__name__,\n",
    "                                                                                                        default_value))\n",
    "                                            kwargs[key] = new_default_val\n",
    "                                    resp = input(\"Select parameter by number (e.g. 0), or ENTER to continue\")\n",
    "                        exec(\"self.{} = ('{}',{})\".format(option_name,specific_val,kwargs)) in locals()\n",
    "                        break\n",
    "                    resp = input(\"Please pick an integer index in range {}\".format(len(abstract_val)))\n",
    "        self.configured = (True, None)\n",
    "        return True\n",
    "\n",
    "    def save_configuration(self, dirPath):\n",
    "        name = input(\"Please select a Configuration name >>>\")\n",
    "        file_path = os.path.join(dirPath, 'configuration{}.pickle'.format(name))\n",
    "        if os.path.exists(file_path):\n",
    "            raise ValueError(\"{} already exists\".format(file_path))\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            pickle.dump(self.__dict__, handle,\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            #pickle.dump(self, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Saved configuration to:\\n{}\".format(file_path))\n",
    "        return file_path\n",
    "\n",
    "    def get(self, attribute, default=None, kwargs=False):\n",
    "        try:\n",
    "            specific_val, kwargs = eval(\"self.{}\".format(attribute))\n",
    "        except:\n",
    "            return default\n",
    "\n",
    "        try:\n",
    "            constraint = eval(\"Config.options.{}\".format(attribute))\n",
    "        except:\n",
    "            constraint = None\n",
    "        if type(constraint) is type:\n",
    "            return constraint(specific_val)\n",
    "        else:\n",
    "            exec(\"import {}\".format('.'.join(specific_val.split('.')[:-1])))\n",
    "            return eval(specific_val), kwargs\n",
    "\n",
    "    def as_dict(self):\n",
    "        return vars(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        info_str = \">>> {} Configuration {} <<<\".format(color.BOLD,color.END)\n",
    "        for key,value in vars(self).items():\n",
    "            if type(value) == tuple:\n",
    "                info_str += \"\\n{0}{2}{1} = {3}\".format(color.BOLD,color.END,key,value[0])\n",
    "                if len(value) == 2:\n",
    "                    if value[1] is not None: info_str += \"\\n\\t**kwargs = {}\".format(value[1])\n",
    "            else:\n",
    "                info_str += \"\\n{} = {}\".format(key,value)\n",
    "        return info_str\n",
    "\n",
    "config_base = Config(options=options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a new hyperparameter Configuration**\n",
    "\n",
    "Species a set of hyper-parameters to be passed into the training pipeline. Where a hyper-parameter is not set, a default value will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config_new = Config()\n",
    "config_new.config_wizard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new confuration to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_new.save_configuration(path.join(os.getcwd(),\"configurations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"assembly\">Load Existing Configuration</a>\n",
    "[Return to Section Content](#arch-content)<br/>\n",
    "**Options**: Specifies which hyper-parameters may be changed. Maps hyper-parameter name to option (type or list)<br />\n",
    "**Configuration**: Specific set of hyper-parameter values. Maps hyper-parameter name to value (function or primitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options(\"basic\",filePath=path.join(os.getcwd(),\"options\",\"options_basic.pickle\"))\n",
    "Config(options=options)\n",
    "config_lookup = {}\n",
    "for i,config_name in enumerate(os.listdir(path.join(os.getcwd(),\"configurations\"))):\n",
    "    print(\"{} : {}\".format(i,config_name))\n",
    "    config_lookup[i] = config_name\n",
    "    \n",
    "resp = input(\"Choose a config by number: \")\n",
    "while True:\n",
    "    if resp.isdigit():\n",
    "        if 0 <= int(resp) < len(config_lookup):\n",
    "            config_name = config_lookup[int(resp)]\n",
    "            break\n",
    "    resp = input(\"Choose a config by number: \")\n",
    "config = Config(file_path=path.join(os.getcwd(),\"configurations\",config_name))\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"Torch_DataSet\">PyTorch Dataset Interface</a>\n",
    "[Return to Section Content](#arch-content)<br/>\n",
    "\n",
    "Defines a custom PyTorch dataset for accessing generated images using their unique ID. Images are uniquely defined by:\n",
    "* Their sequence number (ordered by time during pick-and-place task, later stages will have higher numbers)\n",
    "* Their iteration (a single attempt at pick-and-place)\n",
    "* Their run (a collection of many iterations, named during dataset generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_dir, transforms=transforms.Compose([transforms.ToTensor()])):\n",
    "        \n",
    "        if os.path.exists(dataset_dir):\n",
    "            self.dataset_dir = dataset_dir\n",
    "        else:\n",
    "            raise NameError(\"{} path DNE\".format(dataset_dir))\n",
    "        self.name = os.path.basename(self.dataset_dir)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        counter = 0\n",
    "        with open(path.join(self.dataset_dir,\"metadata.csv\"),\"r\") as f:\n",
    "            self.meta_data = {}\n",
    "            \n",
    "            reader = csv.DictReader(f)\n",
    "            next(reader, None) # Skip Header\n",
    "            for row in reader:\n",
    "                self.meta_data[counter] = row\n",
    "                counter += 1\n",
    "\n",
    "    def __getitem__(self, ID):\n",
    "        \n",
    "        # Given Image ID fetch image\n",
    "        if ID not in self.meta_data: raise NameError(\"{} DNE\".format(ID))\n",
    "        img_name = self.meta_data[ID]['img_name']\n",
    "        img_path = path.join(self.dataset_dir,img_name)\n",
    "        #img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "        img = Image.open(img_path)\n",
    "        img = self.transforms(img)\n",
    "            \n",
    "        label = int(self.meta_data[ID][\"label\"])\n",
    "\n",
    "        return (img,label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Training and Testing Sets**\n",
    "\n",
    "Load a training set containing 80\\% of generated data and a testing set containing 20\\% of generated data. Split is random, hence reseeding may be worthwhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                            std = [0.229, 0.224, 0.225])                                           \n",
    "])\n",
    "\n",
    "dataset = VisualDataset(dataset_dir=path.join(os.getcwd(),\"workspace\",\"data\",\"visualStateV2\"))\n",
    "print(\"{0}{2} dataset size{1}:{3}\".format(color.BOLD,color.END,dataset.name.capitalize(),len(dataset)))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "print(\"{0}Training Set Size{1}: {2}, {0}Testing Set Size{1}: {3}\".format(color.BOLD,color.END,train_size,test_size))\n",
    "trainset,testset = torch.utils.data.random_split(dataset, [train_size,test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                           batch_size=config.get(\"batch_size\",5),\n",
    "                                           shuffle=config.get(\"shuffle\",True))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset,\n",
    "                                          batch_size=config.get(\"batch_size\",5),\n",
    "                                          shuffle=config.get(\"shuffle\",True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect Dataset**\n",
    "\n",
    "Check relative frequencies of each class in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = dataset.meta_data\n",
    "counters = {label.GRASP:0,label.BAD:0,label.NOT_READY:0,label.EMPTY:0}\n",
    "alt_counters={\"failed\":0,\"succeeded\":0}\n",
    "for row in meta_data.values():\n",
    "    counters[label(int(row['label']))] += 1\n",
    "print(counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what percentage of the total data has a specific label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}:{:.2f}%\".format(label.BAD.name,100*counters[label.BAD]/len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load in Classification Architecture**\n",
    "\n",
    "Define neural network architecture, with optional kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture,kwargs = config.get(\"architecture\",(torchvision.models.resnet18,{}))\n",
    "#inspect.getargspec(architecture)\n",
    "print(\"Using {} architecture\".format(architecture.__name__))\n",
    "try:\n",
    "    net = architecture(num_classes=len(label),**kwargs)#\".format(architecture,len(label),kwargs))\n",
    "    print(\"Loaded {} with {} classes and kwargs: {}\".format(architecture.__name__,len(label),kwargs))\n",
    "except:\n",
    "    net = architecture(pretrained=False)\n",
    "    print(\"Loaded architecture does not support num_classes or kwargs parameter, override the input & output layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise functionality of Dataloaders**\n",
    "\n",
    "Show subset of a patch, use to review validity of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_batch(train_loader,frac=0.5,figwidth=10):\n",
    "    (data,target) = next(iter(train_loader))\n",
    "    \n",
    "    nrows=math.ceil(frac*train_loader.batch_size/3)\n",
    "    aspect_ratio = (nrows*246) / (3*468)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=nrows,ncols=3,figsize=(figwidth,aspect_ratio*figwidth))\n",
    "    \n",
    "    for row in range(0,nrows):\n",
    "        for col in range(0,3):\n",
    "            img_data = data[row+col,:,:,:].numpy().swapaxes(0,2).swapaxes(0,1)\n",
    "            axes[row,col].get_xaxis().set_ticks([])\n",
    "            axes[row,col].get_yaxis().set_ticks([])\n",
    "            axes[row,col].set_title(label(target[row+col].item()).name)\n",
    "            [edge.set_color(\"white\") for edge in axes[row,col].spines.values()]\n",
    "            axes[row,col].imshow(img_data)\n",
    "    #fig.suptitle(\"Batch\",fontsize=24,weight='bold')\n",
    "    plt.suptitle(\"Sample Batch | {}/{} images shown\".format(math.ceil(frac*train_loader.batch_size), \n",
    "                train_loader.batch_size), fontsize=22, weight='bold')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "    plt.show()\n",
    "\n",
    "visualise_batch(train_loader,frac=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Neural Network**\n",
    "\n",
    "Run the defined (default:20) number of training epochs, evaluating the performance (and storing the result) at the end of each epoch. Hyper-parameters such as loss and activation are also swapped in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchsnooper\n",
    "\n",
    "#@torchsnooper.snoop()\n",
    "def train(model, device, train_loader, epoch, criterion, optimizer,verbose=False):\n",
    "    model.train()\n",
    "    losses = np.zeros(len(train_loader)) # Remember Losses\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output,target)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        losses[batch_idx] = loss.item() \n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if verbose:\n",
    "                print(\"Outputs:{}\\n{}\".format(output.size(),output))\n",
    "                print(\"Labels:{}\\n{}\".format(target.size(),target))\n",
    "    return losses\n",
    "        \n",
    "def evaluate(model, device, test_loader, criterion, verbose=False):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_correctness = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target).item()\n",
    "            #loss = criterion(output,target).item()\n",
    "            running_loss += loss\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            \n",
    "            correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "            running_correctness += correct\n",
    "            \n",
    "            if verbose: print(\"Number Correct: {} out of {}\".format(correct,len(data)))\n",
    "            #print(pred.view_as(target),target)\n",
    "    # test_loss /= len(test_loader.dataset)\n",
    "    print(\"\"\">>> Evaluation <<<\n",
    "Average Loss: {:.4f}\n",
    "Average Correctness: {:.0f}%\"\"\".format(running_loss/len(test_loader),\n",
    "                                      100*running_correctness/len(test_loader.dataset)))\n",
    "    return 100*running_correctness/len(test_loader.dataset)\n",
    "\n",
    "device = \"cuda\"    \n",
    "print(\"{}Cuda{} is {}\".format(color.BOLD,color.END,\"available\" if torch.cuda.is_available() else \"not available\"))\n",
    "model = net.to(device)\n",
    "optimizer, kwargs = config.get('optimizer',(torch.optim.Adam,{}))        \n",
    "optimizer = optimizer(model.parameters(),**kwargs)\n",
    "loss_func, kwargs = config.get('loss',(torch.nn.MSELoss,{}))   \n",
    "criterion = loss_func(**kwargs)\n",
    "print(\"{0}Loss Function{1}: {2}\\n{0}Optimizer{1}:{3}\".format(color.BOLD,color.END,loss_func.__name__,optimizer))\n",
    "\n",
    "avg_losses = np.zeros(config.get('no_epochs',20))\n",
    "avg_accuracies = np.zeros(config.get('no_epochs',20))\n",
    "for epoch in range(0,config.get('no_epochs',20)):\n",
    "    losses = train(model, device, train_loader, epoch, criterion, optimizer=optimizer,verbose=False)\n",
    "    accuracy = evaluate(model, device, test_loader, criterion, verbose=False)\n",
    "    avg_losses[epoch] = np.mean(losses)\n",
    "    avg_accuracies[epoch] = np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Training Loss\n",
    "\n",
    "Plot a Loss versus Epoch / Accuracy versus Epoch graph, useful to visualise the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mlt\n",
    "font = {'size'   : 24}\n",
    "mlt.rc('font', **font)\n",
    "fig, ax1 = plt.subplots(figsize=(20,14))\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "plt.xticks(range(1,config.get(\"num_epochs\",20)+1))\n",
    "ax1.scatter(range(1,config.get(\"num_epochs\",20)+1),avg_accuracies, color=\"red\", label=\"Accuracy\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.scatter(range(1,config.get(\"num_epochs\",20)+1),avg_losses, color=\"blue\", label=\"Loss\")\n",
    "\n",
    "fig.subplots_adjust(right=0.78)  \n",
    "fig.legend(loc=\"center right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation\n",
    "Evaluate your model on the unseen testing set, use this to see if your model was overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, device, test_loader, criterion, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Trained Model\n",
    "Like the result? Save the model to file for future use. (remember to keep your random split seed handy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = input(\"Choose a name for your model\")\n",
    "torch.save(model,path.join(os.getcwd(),\"models\",\"model_{}\".format(model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lookup = {}\n",
    "for i,model in enumerate(os.listdir(path.join(os.getcwd(),\"models\"))):\n",
    "    print(\"{}: {}\".format(i,model))\n",
    "    model_lookup[i] = model\n",
    "    \n",
    "resp = input(\"Pick a Model by number:\")\n",
    "while True:\n",
    "    if resp.isdigit():\n",
    "        if (0 <= int(resp) < len(model_lookup)):\n",
    "            name = model_lookup[int(resp)]\n",
    "            break\n",
    "    resp = input(\"Pick a Model by its number:\")\n",
    "    \n",
    "model = torch.load(path.join(os.getcwd(),\"models\",name))\n",
    "print(\"Loaded model {}\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Model**\n",
    "\n",
    "Print out PyTorch description of loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
